{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8ddf268",
   "metadata": {},
   "source": [
    "# **Cycle-GAN Consistency**\n",
    "\n",
    "Allucinations are one of the main problems to avoid in generative models and avoid them is an inmediate necessity for a fair integration of AI models to critical environments. In this notebook we explore a metric or explanation that will let us know if the results we are seeing are actually trustworthy or a made up scenario created by the model.\n",
    "\n",
    "Author:  \n",
    "@Jwpr-dpr  \n",
    "23-04-2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c201bf8",
   "metadata": {},
   "source": [
    "## **Introduction: Trusting Super-Resolution GANs through Cycle-Consistency**\n",
    "In recent years, Generative Adversarial Networks (GANs) have become the driving force behind stunning advances in image generation and enhancement. Among these, Super-Resolution GANs (SRGANs) have drawn attention for their ability to take low-resolution (LR) images and transform them into high-resolution (HR) versions that are visually convincing, even photo-realistic.\n",
    "\n",
    "However, this impressive performance comes at a cost: how do we trust what the model is generating? In real-world applications like medical imaging, satellite analysis, or surveillance, a hallucinated detail could mislead decisions. We might get images that look good, but introduce artifacts that never existed in the original scene.\n",
    "\n",
    "* The Problem of Trust in SRGANs  \n",
    "SRGANs prioritize perceptual quality, often using adversarial and perceptual losses. This encourages visually pleasing results, but not necessarily faithful ones. We might get sharper images, but with invented textures and no guarantee that key structures remain intact.\n",
    "\n",
    "So, how can we assess if an SRGAN is not just making things up?\n",
    "\n",
    "* Introducing Cycle-Consistency  \n",
    "The idea of cycle-consistency emerged from CycleGANs, a type of GAN designed for unpaired image translation (like turning a horse into a zebra, and back again). The key concept is:\n",
    "\n",
    "If you transform an image to another domain and then back again, you should end up close to where you started. In the context of image super-resolution we can’t reverse the resolution naturally, but we can simulate it: Upsample with SRGAN, then downsample again.If the downsampled image resembles the original LR input, we’ve preserved structure and avoided hallucination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4163e3",
   "metadata": {},
   "source": [
    "## **Theoretical Framework: Key Concepts Behind CycleGAN and Cycle-Consistency**\n",
    "To understand how cycle-consistency can be used to evaluate models like SRGANs, we first need to revisit a few core ideas from GANs and CycleGANs. This section outlines the most relevant concepts and mathematical formulations.\n",
    "\n",
    "1. Generative Adversarial Networks (GANs)\n",
    "A GAN consists of two neural networks:\n",
    "\n",
    "Generator 𝐺 learns to generate realistic data from random or structured input.\n",
    "Discriminator 𝐷 learns to distinguish between real and fake (generated) data.\n",
    "They are trained in a minimax game, where one tries to fool the other.\n",
    "\n",
    "2. SRGAN: Super-Resolution with Perceptual loss\n",
    "SRGAN enhances low-res images using perceptual loss instead of just pixel-wise loss. The objective combines:\n",
    "\n",
    "* Adversarial loss(realism)\n",
    "* Content loss (perceptual similarity)\n",
    "* Pixel-wise loss (optional)\n",
    "\n",
    "3. CycleGAN and Cycle-Consistency\n",
    "\n",
    "The Idea behind Cycle-GAN consistency is the same as working with functions. Let's say we have a function $f$, that takes inputs (images) from a lower dimentional space $X$ to a higher dimensional space $Y$.\n",
    "\n",
    "$$f:X \\rightarrow Y$$\n",
    "\n",
    "If this function exists, then also must exist an inverse, that means, a function that takes images, from a higher dimensional space $Y$ to a lower dimensional space $X$\n",
    "\n",
    "$$ f^{-1} = g:Y \\rightarrow X $$\n",
    "\n",
    "If we did $f(g(x))$, we have to get our original $x$, as both inverse functions will cancel themselves. Cycle-consistency aims to evaluate that this is acomplished. If we downsample our enhanced image, we should get an image that is almost 100% equal to the original input -maybe some contrast or textures may vary, but not the general structure-, that way we asure that the image integrity is preserved after being enhanced by the model and we didn't get any allucinations being fed into our SR images.\n",
    "\n",
    "This is going to be calculated as a loss, through this expression:\n",
    "\n",
    "$$ l_{cyc} = E_{x~A} \\cdot |F(G(x)) - x| + E_{y~B} \\cdot |G(F(y)) - y| $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a682b98e",
   "metadata": {},
   "source": [
    "## **Implementation**\n",
    "\n",
    "This section we will explore the required tools and libraries, auxiliar functions and the core evaluation function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e76d5a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms.functional import resize\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2e5b118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(img_tensor, scale_factor=4, mode='bicubic'):\n",
    "    \"\"\"\n",
    "    Downsamples a high-resolution image back to low-resolution using interpolation.\n",
    "    \"\"\"\n",
    "    h, w = img_tensor.shape[-2:]\n",
    "    new_h, new_w = h // scale_factor, w // scale_factor\n",
    "    return resize(img_tensor, [new_h, new_w], interpolation=mode)\n",
    "\n",
    "def denormalize(tensor, mean=0.5, std=0.5):\n",
    "    return tensor * std + mean\n",
    "\n",
    "def normalize(tensor, mean=0.5, std=0.5):\n",
    "    return (tensor - mean) / std\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c406f132",
   "metadata": {},
   "source": [
    "Now, we implement the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fbc6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle_consistency_loss(sr_model, lr_img, downsample_fn, scale_factor=4):\n",
    "    \"\"\"\n",
    "    Computes the L1 cycle-consistency loss between the original LR image\n",
    "    and the one obtained after SR -> Downsampling.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        sr_img = sr_model(lr_img)                    # LR -> HR\n",
    "        rec_img = downsample_fn(sr_img, scale_factor) # HR -> LR (reverse)\n",
    "    \n",
    "    loss = F.l1_loss(rec_img, lr_img)\n",
    "    return loss.item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c13227b",
   "metadata": {},
   "source": [
    "All of the aove functions can go to our utils.py module, where we store all of the auxiliar functions for an apporpiate modularization. Finally, this evaluate_cycle_consistency function can be integrated into our evaluate function, so we can see how this metrics evolve epoch by epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb8f515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cycle_consistency(sr_model, dataloader, device, downsample_fn, scale_factor=4):\n",
    "    sr_model.eval()\n",
    "    total_loss = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        lr_imgs = batch.to(device)\n",
    "        loss = cycle_consistency_loss(sr_model, lr_imgs, downsample_fn, scale_factor)\n",
    "        total_loss += loss * lr_imgs.size(0)\n",
    "        num_samples += lr_imgs.size(0)\n",
    "\n",
    "    avg_loss = total_loss / num_samples\n",
    "    return avg_loss\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
